#!/usr/bin/env nix-shell
#! nix-shell -i ansible-playbook --packages ansible

# Ansible Playbook Refs:
# - Syntax: https://docs.ansible.com/ansible/latest/user_guide/playbooks_intro.html#playbook-syntax
# - Collection Index: https://docs.ansible.com/ansible/latest/collections/index.html
# yaml-language-server: $schema=https://raw.githubusercontent.com/ansible/schemas/main/f/ansible.json#/$defs/playbook

# Note: This playbook provisions the Hosts & Virtual Machines for my entire homelab and is designed to be idempotent.

- name: Deploy Apps to docker-server
  hosts: docker-server
  roles:
    - role: vyas.linux.shared_handlers
    - role: vyas.proxmox.shared_handlers
  tasks:
    - name: Creates directory & intermediate directories
      become: true
      ansible.builtin.file:
        path: "{{ item.name }}"
        state: directory
        owner: root
        group: root
        # Set directories as 0770 & files as 0660
        # ref: https://stackoverflow.com/a/29793833
        mode: u=rwX,g=rwX
      loop:
        - name: /opt/apps
        - name: /opt/apps/tfc-agent
    - name: Setup TFC Agent variables
      become: true
      when: false
      ansible.builtin.copy:
        content: |
          TFC_AGENT_TOKEN={{ lookup('community.general.onepassword', 'TFC-Vyas-Agent-Token', field='credential') }}
        dest: /opt/apps/tfc-agent/.env
        owner: root
        group: root
        mode: u=rwX,g=rwX
      notify:
        - RestartTFCAgent
    - name: Setup TFC Agent compose file
      become: true
      ansible.builtin.copy:
        src: opt/apps/tfc-agent/compose.yaml
        dest: /opt/apps/tfc-agent/compose.yaml
        owner: root
        group: root
        mode: u=rwX,g=rwX
      notify:
        - RestartTFCAgent
    - name: Setup SystemD Service
      become: true
      ansible.builtin.copy:
        src: etc/systemd/system/tfc-agent.service
        dest: /etc/systemd/system/tfc-agent.service
        owner: root
        group: root
        mode: "0644"
      notify:
        - SystemDDaemonReload
    - name: Enable SystemD Service
      become: true
      ansible.builtin.systemd_service:
        name: tfc-agent
        state: started
        enabled: true
  handlers:
    - name: RestartTFCAgent
      become: true
      ansible.builtin.systemd_service:
        name: tfc-agent
        daemon_reload: true
        state: restarted

# - name: Deploy Apps to TrueNAS
#   hosts: truenas
#   pre_tasks:
#     - name: Creates directory & intermediate directories
#       ansible.builtin.file:
#         path: "{{ item.name }}"
#         state: directory
#         owner: admin
#         group: root
#         # Set directories as 0770 & files as 0660
#         # ref: https://stackoverflow.com/a/29793833
#         mode: u=rwX,g=rwX
#       loop:
#         - name: /mnt/data1/apps/dockge/stacks
#   vars:
#     apps_fast_data_dir: /mnt/data1/apps
#     apps_safe_data_dir: /mnt/data1/apps
#     apps_dockge_stacks_dir: /mnt/data1/apps/dockge/stacks
#   roles:
#     - role: vyas.compose_deployments.homepage
#     - role: vyas.compose_deployments.tsdproxy
#     - role: vyas.compose_deployments.whats_up_docker
#     - role: vyas.compose_deployments.uptime_kuma
# TODO: find an external-dns system for docker -compose apps
# - name: Deploy Traefik
#   ansible.builtin.import_playbook: ../truenas/apps/traefik/deploy.ansible-playbook.yml

# Provision MaaS
# - name: Provision MaaS
#   hosts: fedora-server
#   roles:
#     - role: vyas.linux.shared_handlers
#     - role: vyas.proxmox.shared_handlers
#     - role: vyas.linux.passwordless_sudo
#       vars:
#         passwordless_sudo_users:
#           - vyas
#   tasks:
#     - name: Install snapd
#       # ref: https://snapcraft.io/install/snapd/fedora#install
#       become: true
#       ansible.builtin.dnf:
#         name:
#           - snapd
#         state: present
#     - name: Install maas snap package
#       become: true
#       community.general.snap:
#         name: maas
#         channel: 3.5/stable

# Provision k8s nodes
- name: Provision fedora & raspberrypi nodes
  # TODO: use all hosts running a linux os
  hosts: k8s:raspberrypi-0:raspberrypi-desktop-0:docker-server
  pre_tasks:
    - name: Check if python3-libdnf5 is installed
      when: ansible_facts['distribution'] == "Fedora"
      shell: dnf list installed python3-libdnf5
      register: check_for_python3_libdnf5
      ignore_errors: true
      changed_when: false

    - name: Bootstrap a host without python dnf pkg installed
      when: ansible_facts['distribution'] == "Fedora" and check_for_python3_libdnf5.rc != 0
      become: true
      ansible.builtin.raw: dnf install -y python3-libdnf5
  roles:
    - role: vyas.linux.shared_handlers
    - role: vyas.proxmox.shared_handlers
    - role: artis3n.tailscale.machine
      # TODO: filter to not include truenas and proxmox nodes
      vars:
        verbose: true
        tailscale_authkey: "{{ lookup('community.general.onepassword', 'Tailscale-Auth-Key (vyas@github)', field='credential') }}"
    - role: vyas.linux.passwordless_sudo
      # TODO: Only run if username == vyas
      vars:
        passwordless_sudo_users:
          - vyas
  tasks: []

# Provision Windows Gaming VM
- name: Provision Windows Gaming VM
  hosts: gaming-vm-win11
  tasks:
    - name: Setup SSH
      # ref: https://docs.ansible.com/ansible/latest/os_guide/windows_ssh.html#key-authentication
      ansible.windows.win_copy:
        src: home/.ssh/authorized_keys
        dest: C:\ProgramData\ssh\administrators_authorized_keys

    - name: Setup Autologin
      block:
        - name: Set Username
          ansible.windows.win_regedit:
            path: HKLM:\SOFTWARE\Microsoft\Windows NT\CurrentVersion\Winlogon
            name: DefaultUserName
            data: "{{ lookup('community.general.onepassword', 'Gaming-VM-Win11', field='username') }}"
        - name: Set Password
          ansible.windows.win_regedit:
            path: HKLM:\SOFTWARE\Microsoft\Windows NT\CurrentVersion\Winlogon
            name: DefaultPassword
            data: "{{ lookup('community.general.onepassword', 'Gaming-VM-Win11') }}"
        - name: Autologin
          ansible.windows.win_regedit:
            path: HKLM:\SOFTWARE\Microsoft\Windows NT\CurrentVersion\Winlogon
            name: AutoAdminLogon
            data: 1
    - name: Set timezone to 'Central Standard Time' (GMT-06:00)
      ansible.windows.win_timezone:
        timezone: Central Standard Time
    - name: Set Windows description, owner and organization
      ansible.windows.win_computer_description:
        description: My gaming Virtual Machine
        owner: Vyas
    - name: Change the hostname
      ansible.windows.win_hostname:
        name: gaming-vm-win11

# Provision Proxmox
- name: Provision Proxmox Hosts
  hosts: proxmox
  vars:
    # TODO: dynamically retrieve this list of CIDR's from Unifi
    my_playbook_advertise_tailscale_cidrs:
      - 192.168.2.0/24
      - 192.168.3.0/24
      - 192.168.4.0/24
      - 192.168.5.0/24
      - 192.168.6.0/24
      - 192.168.7.0/24
  pre_tasks:
    - name: Ensure dmidecode is installed
      become: true
      ansible.builtin.apt:
        package:
          - dmidecode
        state: present
    - name: Check the system chasis type
      shell: dmidecode --string chassis-type
      register: check_system_chassis_type
      ignore_errors: true
      changed_when: false
  roles:
    - role: vyas.proxmox.config_apt_repo
    - role: vyas.linux.shared_handlers
    - role: vyas.proxmox.shared_handlers
    - role: artis3n.tailscale.machine
      vars:
        verbose: true
        tailscale_authkey: "{{ lookup('community.general.onepassword', 'Tailscale-Auth-Key (vyas@github)', field='credential') }}"
        tailscale_args: "--advertise-exit-node --advertise-routes='{{ my_playbook_advertise_tailscale_cidrs | join(',') }}'"
    - role: vyas.proxmox.fix_for_amd_gpu
      # TODO: dynamically detect if the proxmox host has an AMD gpu installed
      # you can `apt install lshw` and then check the output of `lshw -class display -json` for "vendor" : "Advanced Micro Devices, Inc. [AMD/ATI]"
      when: (has_amd_gpu is defined) and has_amd_gpu
  tasks:
    - name: Disable laptop lid close
      # ref: https://youtu.be/FsPYgZYXyZw?si=HgeFVVoom-vbTYcs&t=481
      when: check_system_chassis_type.stdout == "Laptop"
      block:
        - name: Ensure that logind drop-in directory exists
          ansible.builtin.file:
            dest: /etc/systemd/logind.conf.d
            owner: root
            group: root
            mode: "0755"
            state: directory
        - name: Let laptop close lid
          ansible.builtin.copy:
            src: "{{ item.name }}"
            dest: /{{ item.name }}
            owner: root
            group: root
            mode: "0644"
          loop:
            - name: etc/systemd/logind.conf.d/let-laptop-close-lid.conf
          notify:
            - Restart systemd-logind
    - name: Enable VirGL for VMs
      # ref: https://forum.proxmox.com/threads/virtgl-proxmox-7-3-guides-on-how-to-set-up-what-kind-of-performance-to-expect.118575/#post-513957
      block:
        - name: Install VirGL libraries
          ansible.builtin.apt:
            package:
              - libgl1
              - libegl1
            update_cache: true
            state: present
    - name: Fix Disk Usage monitoring
      # TODO: fix
      # Currently the blockinfile keeps inserting it when already present
      when: false
      block:
        - name: Insert code to fix disk usage
          # ref: https://forum.proxmox.com/threads/vm-shows-0-0-disk-usage.114808/
          ansible.builtin.blockinfile:
            path: /usr/share/perl5/PVE/QemuServer.pm
            marker: |
              {% filter indent(width=8, first=true) %}
              ##### CODE TO FETCH VM DISK USAGE FROM CEPH + ZFS POOL {mark} #####
              {% endfilter %}
            insertafter: "# no info available$"
            block: |
              {% filter indent(width=8, first=true) %}
              my @bootdiskorder = split('=', $conf->{boot});
              my @bootdiskname = split(';', $bootdiskorder[1]);
              my @bootdiskinfo = split(",", $conf->{$bootdiskname[0]});
              my @bootdiskdetail = split(":", $bootdiskinfo[0]);
              my $bootdiskstorage = $bootdiskdetail[0];
              my $bootdiskimage = $bootdiskdetail[1];

              if (defined $storecfg->{ids}->{$bootdiskstorage}->{type}) {
                  my $bootdisktype = $storecfg->{ids}->{$bootdiskstorage}->{type};
                  my $bootdiskpool = $storecfg->{ids}->{$bootdiskstorage}->{pool};
                  if ($bootdisktype eq "zfspool") {
                      my $zfsdiskinfocmd ="zfs get -H -p -oname,value  used ".$bootdiskpool."/".$bootdiskimage;
                      my $zfsdiskinfo=`$zfsdiskinfocmd`;
                      $zfsdiskinfo =~ s/\n/""/eg;
                      $zfsdiskinfo =~ s/\r/""/eg;
                      my $total_used_size = 0;
                      if ($zfsdiskinfo =~ /$bootdiskimage/) {
                              my @zfsdiskbytes=split("\t",$zfsdiskinfo);
                              $total_used_size=$zfsdiskbytes[1];
                              }
                      $d->{disk} = $total_used_size;
                      }
                if ($bootdisktype eq "rbd") {
                      my $cephrbddiskinfocmd = "rbd disk-usage -p " . $bootdiskpool . " " . $bootdiskimage . " --format=json";
                      my $cephrbddiskinfo = `$cephrbddiskinfocmd`;
                      $cephrbddiskinfo =~ s/\n/""/eg;
                      $cephrbddiskinfo =~ s/\r/""/eg;
                      $cephrbddiskinfo =~ s/\t/""/eg;
                      $cephrbddiskinfo =~ s/\0/""/eg;
                      $cephrbddiskinfo =~ s/^[a-zA-z0-9,]//g;
                      my $total_used_size = 0;
                      if ($cephrbddiskinfo =~ /$bootdiskimage/) {
                          my $cephrbddiskinfoarray = decode_json($cephrbddiskinfo);
                          foreach my $image (@{$cephrbddiskinfoarray->{'images'}}) {
                              if (defined $image->{'used_size'}) {
                                  $total_used_size += $image->{'used_size'};
                              }
                          }
                          $d->{disk} = $total_used_size;
                      }
                  }
              }
              {% endfilter %}
          notify:
            - RestartPVEStatd
    - name: Setup for PCIe Passthrough
      block:
        - name: Initialize kernel parameters variable
          ansible.builtin.set_fact:
            kernel_parameters:
              - root=ZFS=rpool/ROOT/pve-1
              - boot=zfs
              - iommu=pt
        - name: Template Kernel Parameters
          ansible.builtin.template:
            src: etc/kernel/cmdline.j2
            dest: /etc/kernel/cmdline
            owner: root
            group: root
            mode: "0644"
          notify:
            - Reboot machine
        - name: Initialize kernel modules variable
          ansible.builtin.set_fact:
            kernel_modules:
              - vfio
              - vfio_iommu_type1
              - vfio_pci
        - name: Template kernel modules
          ansible.builtin.template:
            src: etc/modules-load.d/proxmox.conf.j2
            dest: /etc/modules-load.d/proxmox.conf
            owner: root
            group: root
            mode: "0644"
          notify:
            - Refresh initramfs
    - name: Install Tools
      ansible.builtin.apt:
        package:
          - fish
          - lldpd
        update_cache: true
        state: present
    - name: Make web interface accessible from standard HTTP/HTTPS ports
      block:
        - name: Install caddy
          ansible.builtin.apt:
            package:
              - caddy
            state: present
        - name: Create a new caddy config file
          vars:
            proxmox_fqdn_hostname: "{{ ansible_hostname }}.hosts.vyas-n.dev"
          ansible.builtin.template:
            src: "{{ item.name }}.j2"
            dest: /{{ item.name }}
            owner: root
            group: root
            mode: "0644"
          loop:
            - name: etc/caddy/Caddyfile
          notify:
            - ReloadCaddy
            # TODO: notify to validate Caddy config
        - name: Ensure that caddy systemd service override directory exists
          ansible.builtin.file:
            dest: /etc/systemd/system/caddy.service.d
            owner: root
            group: root
            mode: "0755"
            state: directory
        - name: Ensure that caddy only gets started after proxmox has started
          vars:
            proxmox_fqdn_hostname: proxmox-1.hosts.vyas-n.dev
          ansible.builtin.copy:
            src: "{{ item.name }}"
            dest: /{{ item.name }}
            owner: root
            group: root
            mode: "0644"
          loop:
            - name: etc/systemd/system/caddy.service.d/override.conf
          notify:
            - SystemDDaemonReload
        - name: Ensure caddy is enabled & started
          ansible.builtin.systemd_service:
            name: caddy
            state: started
            enabled: true

    - name: Cleanup Nginx
      # We now use Caddy for reverse proxy functionality
      block:
        - name: Remove nginx pkg
          become: true
          ansible.builtin.apt:
            package:
              - nginx
            state: absent
            purge: true
        # TODO: purge should already get rid of these, but just in-case
        # - name: Remove nginx directories & related systemd configs
        #   become: true
        #   ansible.builtin.file:
        #     path: /etc/nginx
        #     state: absent
  handlers:
    # TODO: add a notify to validate Caddy config
    - name: ReloadCaddy
      become: true
      ansible.builtin.systemd_service:
        name: caddy
        state: reloaded
